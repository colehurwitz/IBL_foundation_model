model_class: DECODER

reduced_rank:
  temporal_rank: 2

mlp:
  mlp_hidden_size: (128, 64, 32)
  drop_out: 0.1

lstm:
  lstm_n_layers: 1
  lstm_hidden_size: 32
  mlp_hidden_size: (32)
  drop_out: 0.1
    